{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_path = os.path.join(path, \"seg_train\", \"seg_train\")\n",
    "test_path = os.path.join(path, \"seg_test\", \"seg_test\")\n",
    "predict_path = os.path.join(path, \"seg_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 128\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la chargement du dataset nous utilison la fonction suivant : `image_dataset_from_directory`\n",
    "\n",
    "Elle permet de directement d'avoir :\n",
    "- un chargement efficace des images\n",
    "- des prétraitements intégrés\n",
    "- et une optimisation avec TensorFlow\n",
    "\n",
    "Voici une explication des paramètres importants : \n",
    "\n",
    "|                 **Paramètre**                \t|                           **Description**                          \t|\n",
    "|:--------------------------------------------:\t|:------------------------------------------------------------------:\t|\n",
    "| `directory`                                  \t| Chemin du dataset.                                                 \t|\n",
    "| `labels=\"inferred\"`                          \t| Déduit les labels des noms de sous-dossiers.                       \t|\n",
    "| `label_mode=\"int\"`                           \t| Les labels sont encodés comme des entiers.                         \t|\n",
    "| `batch_size=32`                              \t| Nombre d’images chargées par batch.                                \t|\n",
    "| `image_size=(150,150)`                       \t| Redimensionne les images à cette taille.                           \t|\n",
    "| `validation_split=0.2`                       \t| Réserve 20% des images pour la validation.                         \t|\n",
    "| `subset=\"training\"`<br>`subset=\"validation\"` \t| Permet de séparer le dataset.                                      \t|\n",
    "| `shuffle=True`                               \t| Mélange les images pour éviter les biais.                          \t|\n",
    "| `seed=42`                                    \t| Assure que le split train/val est reproductible en fixant la seed. \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **train / validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_dateset\n",
    "Permet d'enseigner au modèle à reconnaître les images, est utilisé durant l'entraînement du modèle (`modele.fit()`) et contient 80% des données d'entraînement.\n",
    "\n",
    "## val_dataset\n",
    "Permet de vérifier la performance du modèle pendant l'entraînement, afin de détecter l’overfitting (si la perte val_loss augmente mais train_loss diminue) et d'ajuster les hyperparamètres (nombre de couches, learning rate, data augmentation, etc.). Il contient 20% des données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,  # 80% train / 20% validation\n",
    "    subset=\"both\",\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **test**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_dataset\n",
    "Permet de mesurer la vraie performance du modèle après l'entraînement, afin de calculer la pprécision et de voir comment le modèle se comporte sur des images qu'il n'a jamais vues. Il contient des images inédites labelisées, on l'utilise avec `model.evaluate(test_dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **prédiction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_dataset\n",
    "Permet de faire des prédictions sur des images sans labels. , on l'utilise avec `model.predict(predict_dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = keras.utils.image_dataset_from_directory(\n",
    "    predict_path,\n",
    "    labels=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation (ou augmentation de données) est une technique qui génère des variations artificielles des images d'entraînement. Cela permet d’augmenter la diversité des données sans collecter plus d’images. Elle seulement est appliqué sur le dataset d'entraînement.\n",
    "\n",
    "|    **Paramètre**    \t|                 **Description**                 \t|\n",
    "|:-------------------:\t|:-----------------------------------------------:\t|\n",
    "| `RandomFlip`        \t| Retourne l’image horizontalement/verticalement. \t|\n",
    "| `RandomRotation`    \t| Fait tourner légèrement l’image.                \t|\n",
    "| `RandomZoom`        \t| Simule un zoom avant/arrière.                   \t|\n",
    "| `RandomBrightness`  \t| Change la luminosité.                           \t|\n",
    "| `RandomContrast`    \t| Modifie le contraste.                           \t|\n",
    "| `RandomTranslation` \t| Déplace légèrement l’image.                     \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_layers = [\n",
    "    keras.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
    "    keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
    "    keras.layers.RandomContrast(factor=0.2),\n",
    "    keras.layers.RandomBrightness(factor=0.2),\n",
    "    keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\")\n",
    "]\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(augmented_images[0]).astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application de l'augmentation de donnée sur le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos images ont déjà une taille standard (150x150). Cependant, les valeurs de leurs canaux RGB se situent dans la plage [0, 255]. Ce n'est pas l'idéal pour un réseau neuronal ; en général, il faut chercher à réduire les valeurs d'entrée. Ici, nous normaliserons les valeurs pour qu'elles se situent dans la plage [0, 1] en utilisant une couche de mise à l'échelle au début de notre modèle avec : `x = keras.layers.Rescaling(1.0 / 255)(inputs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        x = keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=IMG_SIZE + (3,), num_classes=6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un callback est une fonction qui intervient automatiquement pendant l'entraînement du modèle. Il permet de contrôler et améliorer l’entraînement en temps réel.\n",
    "\n",
    "Ils sont appelés à différents moments :\n",
    "- Avant ou après chaque batch (on_batch_end)\n",
    "- Avant ou après chaque epoch (on_epoch_end)\n",
    "- Avant ou après l’entraînement complet (on_train_end)\n",
    "\n",
    "\n",
    "|       **Callback**      \t|                                              **Description**                                             \t|\n",
    "|:-----------------------:\t|:--------------------------------------------------------------------------------------------------------:\t|\n",
    "| `ModelCheckpoint`       \t| Sauvegarde automatiquement le meilleur modèle basé sur `val_accuracy`.                                   \t|\n",
    "| `BackupAndRestore`      \t| Permet de reprendre l'entraînement en cas d'arrêt accidentel.                                            \t|\n",
    "| `TerminateOnNaN`        \t| Stoppe immédiatement si `loss` devient NaN.                                                              \t|\n",
    "| `EarlyStopping`         \t| Arrête l'entraînement si l'amélioration ralentit, évite l'overfitting et réduit le temps d'entraînement. \t|\n",
    "| `ReduceLROnPlateau`     \t| Réduit automatiquement le `learning rate` si `val_loss` stagne.                                          \t|\n",
    "| `LearningRateScheduler` \t| Change dynamiquement le `learning rate` selon une fonction.                                              \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('from_scratch_cnn_model.keras', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "    keras.callbacks.BackupAndRestore(backup_dir='./backup'),\n",
    "    keras.callbacks.TerminateOnNaN(),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=60,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(history):\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy: 0.7093\n",
    "Test Loss: 1.1856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image_path(folder_path):\n",
    "    try:\n",
    "        files = os.listdir(folder_path)\n",
    "        # Filter the list to get only image files\n",
    "        images = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "\n",
    "        if not images:\n",
    "            print(\"No images found in the specified folder.\")\n",
    "            print(f\"Folder path: {folder_path}\")\n",
    "            return None\n",
    "\n",
    "        # Choose a random image file\n",
    "        random_image = random.choice(images)\n",
    "        random_image_path = os.path.join(folder_path, random_image)\n",
    "        return random_image_path\n",
    "      \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while selecting image randomly: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(get_random_image_path(predict_path + \"/seg_pred\"))\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = keras.ops.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "\n",
    "class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "predicted_label = class_names[predicted_class]\n",
    "\n",
    "print(f\"🏆 Representation : {predicted_label} with {100 * tf.reduce_max(predictions):.2f}% confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle via transfer learning avec EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "efficient_net_model = keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "efficient_net_model.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(efficient_net_model.output)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.Dropout(0.2, name=\"top_dropout\")(x)\n",
    "outputs = keras.layers.Dense(6, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "efficient_net_model = keras.Model(inputs=inputs, outputs=outputs, name=\"EfficientNet\")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "efficient_net_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net_history = efficient_net_model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "plot_hist(efficient_net_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
