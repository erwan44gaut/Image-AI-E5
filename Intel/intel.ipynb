{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_path = os.path.join(path, \"seg_train\", \"seg_train\")\n",
    "test_path = os.path.join(path, \"seg_test\", \"seg_test\")\n",
    "predict_path = os.path.join(path, \"seg_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 128\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la chargement du dataset nous utilison la fonction suivant : `image_dataset_from_directory`\n",
    "\n",
    "Elle permet de directement d'avoir :\n",
    "- un chargement efficace des images\n",
    "- des pr√©traitements int√©gr√©s\n",
    "- et une optimisation avec TensorFlow\n",
    "\n",
    "Voici une explication des param√®tres importants : \n",
    "\n",
    "|                 **Param√®tre**                \t|                           **Description**                          \t|\n",
    "|:--------------------------------------------:\t|:------------------------------------------------------------------:\t|\n",
    "| `directory`                                  \t| Chemin du dataset.                                                 \t|\n",
    "| `labels=\"inferred\"`                          \t| D√©duit les labels des noms de sous-dossiers.                       \t|\n",
    "| `label_mode=\"int\"`                           \t| Les labels sont encod√©s comme des entiers.                         \t|\n",
    "| `batch_size=32`                              \t| Nombre d‚Äôimages charg√©es par batch.                                \t|\n",
    "| `image_size=(150,150)`                       \t| Redimensionne les images √† cette taille.                           \t|\n",
    "| `validation_split=0.2`                       \t| R√©serve 20% des images pour la validation.                         \t|\n",
    "| `subset=\"training\"`<br>`subset=\"validation\"` \t| Permet de s√©parer le dataset.                                      \t|\n",
    "| `shuffle=True`                               \t| M√©lange les images pour √©viter les biais.                          \t|\n",
    "| `seed=42`                                    \t| Assure que le split train/val est reproductible en fixant la seed. \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **train / validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_dateset\n",
    "Permet d'enseigner au mod√®le √† reconna√Ætre les images, est utilis√© durant l'entra√Ænement du mod√®le (`modele.fit()`) et contient 80% des donn√©es d'entra√Ænement.\n",
    "\n",
    "## val_dataset\n",
    "Permet de v√©rifier la performance du mod√®le pendant l'entra√Ænement, afin de d√©tecter l‚Äôoverfitting (si la perte val_loss augmente mais train_loss diminue) et d'ajuster les hyperparam√®tres (nombre de couches, learning rate, data augmentation, etc.). Il contient 20% des donn√©es d'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,  # 80% train / 20% validation\n",
    "    subset=\"both\",\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **test**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_dataset\n",
    "Permet de mesurer la vraie performance du mod√®le apr√®s l'entra√Ænement, afin de calculer la ppr√©cision et de voir comment le mod√®le se comporte sur des images qu'il n'a jamais vues. Il contient des images in√©dites labelis√©es, on l'utilise avec `model.evaluate(test_dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset de **pr√©diction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_dataset\n",
    "Permet de faire des pr√©dictions sur des images sans labels. , on l'utilise avec `model.predict(predict_dataset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = keras.utils.image_dataset_from_directory(\n",
    "    predict_path,\n",
    "    labels=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation (ou augmentation de donn√©es) est une technique qui g√©n√®re des variations artificielles des images d'entra√Ænement. Cela permet d‚Äôaugmenter la diversit√© des donn√©es sans collecter plus d‚Äôimages. Elle seulement est appliqu√© sur le dataset d'entra√Ænement.\n",
    "\n",
    "|    **Param√®tre**    \t|                 **Description**                 \t|\n",
    "|:-------------------:\t|:-----------------------------------------------:\t|\n",
    "| `RandomFlip`        \t| Retourne l‚Äôimage horizontalement/verticalement. \t|\n",
    "| `RandomRotation`    \t| Fait tourner l√©g√®rement l‚Äôimage.                \t|\n",
    "| `RandomZoom`        \t| Simule un zoom avant/arri√®re.                   \t|\n",
    "| `RandomBrightness`  \t| Change la luminosit√©.                           \t|\n",
    "| `RandomContrast`    \t| Modifie le contraste.                           \t|\n",
    "| `RandomTranslation` \t| D√©place l√©g√®rement l‚Äôimage.                     \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_layers = [\n",
    "    keras.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
    "    keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
    "    keras.layers.RandomContrast(factor=0.2),\n",
    "    keras.layers.RandomBrightness(factor=0.2),\n",
    "    keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2, fill_mode=\"reflect\", interpolation=\"bilinear\")\n",
    "]\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(augmented_images[0]).astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application de l'augmentation de donn√©e sur le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cr√©ation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos images ont d√©j√† une taille standard (150x150). Cependant, les valeurs de leurs canaux RGB se situent dans la plage [0, 255]. Ce n'est pas l'id√©al pour un r√©seau neuronal ; en g√©n√©ral, il faut chercher √† r√©duire les valeurs d'entr√©e. Ici, nous normaliserons les valeurs pour qu'elles se situent dans la plage [0, 1] en utilisant une couche de mise √† l'√©chelle au d√©but de notre mod√®le avec : `x = keras.layers.Rescaling(1.0 / 255)(inputs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "        x = keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        x = keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=IMG_SIZE + (3,), num_classes=6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entra√Ænement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un callback est une fonction qui intervient automatiquement pendant l'entra√Ænement du mod√®le. Il permet de contr√¥ler et am√©liorer l‚Äôentra√Ænement en temps r√©el.\n",
    "\n",
    "Ils sont appel√©s √† diff√©rents moments :\n",
    "- Avant ou apr√®s chaque batch (on_batch_end)\n",
    "- Avant ou apr√®s chaque epoch (on_epoch_end)\n",
    "- Avant ou apr√®s l‚Äôentra√Ænement complet (on_train_end)\n",
    "\n",
    "\n",
    "|       **Callback**      \t|                                              **Description**                                             \t|\n",
    "|:-----------------------:\t|:--------------------------------------------------------------------------------------------------------:\t|\n",
    "| `ModelCheckpoint`       \t| Sauvegarde automatiquement le meilleur mod√®le bas√© sur `val_accuracy`.                                   \t|\n",
    "| `BackupAndRestore`      \t| Permet de reprendre l'entra√Ænement en cas d'arr√™t accidentel.                                            \t|\n",
    "| `TerminateOnNaN`        \t| Stoppe imm√©diatement si `loss` devient NaN.                                                              \t|\n",
    "| `EarlyStopping`         \t| Arr√™te l'entra√Ænement si l'am√©lioration ralentit, √©vite l'overfitting et r√©duit le temps d'entra√Ænement. \t|\n",
    "| `ReduceLROnPlateau`     \t| R√©duit automatiquement le `learning rate` si `val_loss` stagne.                                          \t|\n",
    "| `LearningRateScheduler` \t| Change dynamiquement le `learning rate` selon une fonction.                                              \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('from_scratch_cnn_model.keras', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "    keras.callbacks.BackupAndRestore(backup_dir='./backup'),\n",
    "    keras.callbacks.TerminateOnNaN(),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=60,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(history):\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy: 0.7093\n",
    "Test Loss: 1.1856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image_path(folder_path):\n",
    "    try:\n",
    "        files = os.listdir(folder_path)\n",
    "        # Filter the list to get only image files\n",
    "        images = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "\n",
    "        if not images:\n",
    "            print(\"No images found in the specified folder.\")\n",
    "            print(f\"Folder path: {folder_path}\")\n",
    "            return None\n",
    "\n",
    "        # Choose a random image file\n",
    "        random_image = random.choice(images)\n",
    "        random_image_path = os.path.join(folder_path, random_image)\n",
    "        return random_image_path\n",
    "      \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while selecting image randomly: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(get_random_image_path(predict_path + \"/seg_pred\"))\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = keras.ops.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "\n",
    "class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "predicted_label = class_names[predicted_class]\n",
    "\n",
    "print(f\"üèÜ Representation : {predicted_label} with {100 * tf.reduce_max(predictions):.2f}% confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod√®le via transfer learning avec EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "efficient_net_model = keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "efficient_net_model.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(efficient_net_model.output)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = keras.layers.Dropout(0.2, name=\"top_dropout\")(x)\n",
    "outputs = keras.layers.Dense(6, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "efficient_net_model = keras.Model(inputs=inputs, outputs=outputs, name=\"EfficientNet\")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "efficient_net_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net_history = efficient_net_model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "plot_hist(efficient_net_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
